@Article{Lagriffoul_2016,
  author    = {Fabien Lagriffoul and Benjamin Andres},
  journal   = {The International Journal of Robotics Research},
  title     = {Combining task and motion planning: A culprit detection problem},
  year      = {2016},
  month     = {jan},
  number    = {8},
  pages     = {890--927},
  volume    = {35},
  doi       = {10.1177/0278364915619022},
  groups    = {therring:1},
  publisher = {{SAGE} Publications},
}

@Article{garrett_ffrob,
  author       = {Caelan Reed Garrett and Tomas Lozano-Perez and Leslie Pack Kaelbling},
  title        = {FFRob: Leveraging Symbolic Planning for Efficient Task and Motion Planning},
  abstract     = {Mobile manipulation problems involving many objects are challenging to solve due to the high dimensionality and multi-modality of their hybrid configuration spaces. Planners that perform a purely geometric search are prohibitively slow for solving these problems because they are unable to factor the configuration space. Symbolic task planners can efficiently construct plans involving many variables but cannot represent the geometric and kinematic constraints required in manipulation. We present the FFRob algorithm for solving task and motion planning problems. First, we introduce Extended Action Specification (EAS) as a general purpose planning representation that supports arbitrary predicates as conditions. We adapt existing heuristic search ideas for solving \proc{strips} planning problems, particularly delete-relaxations, to solve EAS problem instances. We then apply the EAS representation and planners to manipulation problems resulting in FFRob. FFRob iteratively discretizes task and motion planning problems using batch sampling of manipulation primitives and a multi-query roadmap structure that can be conditionalized to evaluate reachability under different placements of movable objects. This structure enables the EAS planner to efficiently compute heuristics that incorporate geometric and kinematic planning constraints to give a tight estimate of the distance to the goal. Additionally, we show FFRob is probabilistically complete and has finite expected runtime. Finally, we empirically demonstrate FFRob's effectiveness on complex and diverse task and motion planning tasks including rearrangement planning and navigation among movable objects.},
  date         = {2016-08-03},
  doi          = {10.1177/0278364917739114},
  eprint       = {1608.01335v2},
  eprintclass  = {cs.RO},
  eprinttype   = {arXiv},
  file         = {:/home/therring/Workspace/bibtexes/lozano_kaelbling/ffrob.pdf:PDF;online:http\://arxiv.org/pdf/1608.01335v2:PDF},
  groups       = {therring:1},
  journaltitle = {The International Journal of Robotics Research (IJRR), 2017},
  keywords     = {cs.RO},
}

@Article{Driess_2020,
  author      = {Danny Driess and Jung-Su Ha and Marc Toussaint},
  journal     = {Robotics: Science and Systems (R:SS) 2020},
  title       = {Deep Visual Reasoning: Learning to Predict Action Sequences for Task and Motion Planning from an Initial Scene Image},
  year        = {2020},
  abstract    = {In this paper, we propose a deep convolutional recurrent neural network that predicts action sequences for task and motion planning (TAMP) from an initial scene image. Typical TAMP problems are formalized by combining reasoning on a symbolic, discrete level (e.g. first-order logic) with continuous motion planning such as nonlinear trajectory optimization. Due to the great combinatorial complexity of possible discrete action sequences, a large number of optimization/motion planning problems have to be solved to find a solution, which limits the scalability of these approaches. To circumvent this combinatorial complexity, we develop a neural network which, based on an initial image of the scene, directly predicts promising discrete action sequences such that ideally only one motion planning problem has to be solved to find a solution to the overall TAMP problem. A key aspect is that our method generalizes to scenes with many and varying number of objects, although being trained on only two objects at a time. This is possible by encoding the objects of the scene in images as input to the neural network, instead of a fixed feature vector. Results show runtime improvements of several magnitudes. Video: https://youtu.be/i8yyEbbvoEk},
  date        = {2020-06-09},
  eprint      = {2006.05398v1},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:deep_visual_reasoning.pdf:PDF;online:http\://arxiv.org/pdf/2006.05398v1:PDF},
  groups      = {therring:1},
  keywords    = {cs.LG, cs.AI, cs.CV, cs.RO, stat.ML},
}

@Article{Gerkey_2004,
  author    = {Brian P. Gerkey and Maja J. Matari{\'{c}}},
  journal   = {The International Journal of Robotics Research},
  title     = {A Formal Analysis and Taxonomy of Task Allocation in Multi-Robot Systems},
  year      = {2004},
  month     = {sep},
  number    = {9},
  pages     = {939--954},
  volume    = {23},
  doi       = {10.1177/0278364904045564},
  file      = {:formal_analysis_taxonomy_task_allocation_multi.pdf:PDF;:http\://robotics.stanford.edu/~gerkey/research/final_papers/mrta-taxonomy.pdf:URL},
  groups    = {therring:1},
  publisher = {{SAGE} Publications},
}

@Article{shome_2020,
  author      = {Rahul Shome and Kostas E. Bekris},
  journal     = {Workshop on the Algorithmic Foundations of Robotics (WAFR) 2021},
  title       = {Synchronized Multi-Arm Rearrangement Guided by Mode Graphs with Capacity Constraints},
  year        = {2021},
  abstract    = {Solving task planning problems involving multiple objects and multiple robotic arms poses scalability challenges. Such problems involve not only coordinating multiple high-DoF arms, but also searching through possible sequences of actions including object placements, and handoffs. The current work identifies a useful connection between multi-arm rearrangement and recent results in multi-body path planning on graphs with vertex capacity constraints. Solving a synchronized multi-arm rearrangement at a high-level involves reasoning over a modal graph, where nodes correspond to stable object placements and object transfer states by the arms. Edges of this graph correspond to pick, placement and handoff operations. The objects can be viewed as pebbles moving over this graph, which has capacity constraints. For instance, each arm can carry a single object but placement locations can accumulate many objects. Efficient integer linear programming-based solvers have been proposed for the corresponding pebble problem. The current work proposes a heuristic to guide the task planning process for synchronized multi-arm rearrangement. Results indicate good scalability to multiple arms and objects, and an algorithm that can find high-quality solutions fast and exhibiting desirable anytime behavior.},
  date        = {2020-05-18},
  eprint      = {2005.09127v1},
  eprintclass = {cs.RO},
  eprinttype  = {arXiv},
  file        = {:synchronized_multi_arm_rearrangement.pdf:PDF;online:http\://arxiv.org/pdf/2005.09127v1:PDF},
  groups      = {therring:1},
  keywords    = {cs.RO},
}

@Article{choudhury_2020,
  author      = {Shushman Choudhury and Jayesh K. Gupta and Mykel J. Kochenderfer and Dorsa Sadigh and Jeannette Bohg},
  title       = {Dynamic Multi-Robot Task Allocation under Uncertainty and Temporal Constraints},
  journal     = {Robotics Science and Systems (RSS) 2020},
  year        = {2020},
  abstract    = {We consider the problem of dynamically allocating tasks to multiple agents under time window constraints and task completion uncertainty. Our objective is to minimize the number of unsuccessful tasks at the end of the operation horizon. We present a multi-robot allocation algorithm that decouples the key computational challenges of sequential decision-making under uncertainty and multi-agent coordination and addresses them in a hierarchical manner. The lower layer computes policies for individual agents using dynamic programming with tree search, and the upper layer resolves conflicts in individual plans to obtain a valid multi-agent allocation. Our algorithm, Stochastic Conflict-Based Allocat